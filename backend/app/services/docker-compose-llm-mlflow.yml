version: '3.8'

services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.8.0
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - mlflow-data:/mlflow
    command: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlflow/artifacts --host 0.0.0.0 --port 5000
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:5000/api/2.0/mlflow/experiments/list || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - llm-network

  llm-service:
    build:
      context: ../../..
      dockerfile: backend/app/services/Dockerfile.llm-mlflow
    ports:
      - "8080:8080"
    volumes:
      - /path/to/your/models:/models
      - mlflow-artifacts:/app/mlflow-artifacts
    environment:
      - MODEL_PATH=/models/your-model-directory
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_EXPERIMENT_NAME=llm-experiments
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      mlflow:
        condition: service_healthy
    healthcheck:
      test: curl -f http://localhost:8080/health || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    networks:
      - llm-network

  experiment-dashboard:
    image: python:3.10-slim
    working_dir: /app
    volumes:
      - ./examples:/app/examples
      - mlflow-artifacts:/mlflow-artifacts
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    command: >
      bash -c "pip install requests pandas matplotlib mlflow &&
               python -m http.server 8088"
    ports:
      - "8088:8088"
    depends_on:
      - mlflow
      - llm-service
    networks:
      - llm-network

volumes:
  mlflow-data:
  mlflow-artifacts:

networks:
  llm-network:
    driver: bridge 